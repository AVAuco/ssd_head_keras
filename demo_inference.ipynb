{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssd_people head detector inference demo\n",
    "\n",
    "This is a brief tutorial that shows how to use our Single Shot Multibox Detector (SSD) based detector for head detection on images."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Setup\n",
    "First, we import the libraries required to load images and setup the SSD head detector for inference. This model has been trained using [Pierluigi Ferrari's SSD implementation](https://github.com/pierluigiferrari/ssd_keras/), of which we include the required code in this repository. We refer you to the original implementation in case of an issue with that code.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "# from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "# \n",
    "# from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "# from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "# from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "# from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This model uses a 512x512 input size, let's set our image size to that resolution size:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the image size.\n",
    "img_height = 512\n",
    "img_width = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are two different inference modes: the mode \"`inference`\" uses the original implementation's algorithm, which is slower but more precise, while the \"`inference_fast`\" mode is much faster at the cost of precision. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Set the model's inference mode\n",
    "model_mode = 'inference'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained SSD model\n",
    "In order to run the head detection model first you must download the `.h5` file that contains the model and the trained weights. To do so, run the code in [section 1.1](#download_cell).\n",
    "\n",
    "Once downloaded, you can either build a new model and load the trained weights into it ([section 1.2](#build_cell)) or just load the ready to use model ([section 1.3](#load_cell)). The first option allows you to configure some model parameters, while the latter loads the original model's configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='download_cell'></a>\n",
    "### 1.1 Download the model's .h5 file\n",
    "First, we download the model's file from the server to this repository's `data/models` directory. We provide a simple script which will do this task for you, which you can execute by running the next cell. NOTE: this script requires `curl`to be installed in your system. \n",
    "\n",
    "In case you prefer to download the model manually, you can download it using the following [link](https://drive.google.com/open?id=12cqKTPtQBAu780219hEbST7VwQuf6xDH)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "# Download the model file into the \"data\" directory\n",
    "os.chdir('./data/')\n",
    "if 'download_model.sh' in os.listdir(os.getcwd()):\n",
    "    print(\"Downloading model...\")\n",
    "    subprocess.call(\"./download_model.sh\")\n",
    "    print(\"Download finished.\")\n",
    "# Restore the working directory path\n",
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='build_cell'></a>\n",
    "### 1.2 Build the model and load the trained weights into it\n",
    "You can build a new model and load the provided weights into it, which allows some degree of personalization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 0: Set the desired confidence threshold\n",
    "# Set a value in range [0, 1], a higher value decreases the number of detections produced by the model and increases its\n",
    "# speed during inference\n",
    "conf_thresh = 0.01\n",
    "\n",
    "# 1: Build the Keras model\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "model = ssd_512(image_size=(img_height, img_width, 3),\n",
    "                n_classes=1,\n",
    "                mode=model_mode,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # PASCAL VOC\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=[2, 1, 0],\n",
    "               confidence_thresh=conf_thresh,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "# 2: Load the trained weights into the model. Make sure the path correctly points to the model's .h5 file\n",
    "weights_path = './data/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187.h5'\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "# 4: OPTIONAL Save compiled model in inference mode so we can use option 1.3 in future executions\n",
    "# model.save('./data/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='load_cell'></a>\n",
    "### 1.3 Load the model as-is\n",
    "This option loads the downloaded model as it was compiled.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the path correctly points to the model's .h5 file\n",
    "weights_path = './data/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187.h5'\n",
    "\n",
    "# Create an SSDLoss object in order to pass that to the model loader\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, n_neg_min=0, alpha=1.0)\n",
    "\n",
    "# Clear previous models from memory.\n",
    "K.clear_session() \n",
    "\n",
    "# Finally load the model\n",
    "model = load_model(weights_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                                 'L2Normalization': L2Normalization,\n",
    "                                                 'DecodeDetections': DecodeDetections,\n",
    "                                                 'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load example images\n",
    "\n",
    "Load some images for which you'd like the model to make predictions. There are some demo images available in this repository's `examples`directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original images array\n",
    "orig_images = [] \n",
    "# Resized images array\n",
    "input_images = []\n",
    "\n",
    "# We'll only load one image in this example.\n",
    "img_path = 'examples/people_drinking.jpg'\n",
    "# img_path = 'examples/fish_bike.jpg'\n",
    "# img_path = 'examples/mounted_police.jpg'\n",
    "# img_path = 'examples/rugby_players'\n",
    "\n",
    "# Load the original image (used to display results)\n",
    "orig_images.append(image.load_img(img_path))\n",
    "# orig_images.append(image.load_img(img_path))\n",
    "# Load the image resized to the model's input size\n",
    "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "img = image.img_to_array(img)\n",
    "input_images.append(img)\n",
    "input_images = np.array(input_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions\n",
    "Now we feed the example images into the network to obtain the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(input_images)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred` contains a fixed number of predictions per batch item (200 if you use the original model configuration), many of which are low-confidence predictions or dummy entries. We therefore need to apply a confidence threshold to filter out the bad predictions. Set this confidence threshold value how you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.25\n",
    "\n",
    "# Perform confidence thresholding.\n",
    "y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "\n",
    "# Convert the predictions for the original image.\n",
    "# y_pred_thresh_inv = apply_inverse_transforms(y_pred_thresh, batch_inverse_transforms)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_thresh[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the predictions\n",
    "\n",
    "We just resized the input image above and made predictions on the distorted image. We'd like to visualize the predictions on the image in its original size though, so below we'll transform the coordinates of the predicted boxes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display the image and draw the predicted boxes onto it.\n",
    "\n",
    "# Set the colors for the bounding boxes\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "classes = ['background', 'head']\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.imshow(orig_images[0])\n",
    "\n",
    "current_axis = plt.gca()\n",
    "\n",
    "for box in y_pred_thresh[0]:\n",
    "    # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "    xmin = box[2] * np.array(orig_images[0]).shape[1] / img_width\n",
    "    ymin = box[3] * np.array(orig_images[0]).shape[0] / img_height\n",
    "    xmax = box[4] * np.array(orig_images[0]).shape[1] / img_width\n",
    "    ymax = box[5] * np.array(orig_images[0]).shape[0] / img_height\n",
    "    color = colors[int(box[0])]\n",
    "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
    "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}