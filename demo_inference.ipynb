{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssd_people head detector inference demo\n",
    "This is a brief tutorial that shows how to use our Single Shot Multibox Detector (SSD) based detector for head detection on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 0. Setup\n",
    "First, we import the libraries required to load images and setup the SSD head detector for inference. This model has been trained using [Pierluigi Ferrari's SSD implementation](https://github.com/pierluigiferrari/ssd_keras/), of which we include the required code in this repository. We refer you to the original implementation in case of an issue with that code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since there are differences in the object serialization methods used between Python versions previous to version 3.6, we provide two different versions of our model. In order to determine which version should be used, please run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "py_version = ''.join(python_version().split('.'))\n",
    "model_version = '3.6'\n",
    "if int(py_version) < 360:\n",
    "    model_version = '3.5'\n",
    "print('Using model version for Python %s.' % model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a 512x512 input size, let's set our image size to that resolution size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the image size.\n",
    "img_height = 512\n",
    "img_width = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are two different inference modes: the mode `inference` uses the original implementation's algorithm, which is slower but more precise, while the \"`inference_fast`\" mode is much faster at the cost of precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the model's inference mode\n",
    "model_mode = 'inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we set the model's confidence threshold value, i.e. the model will only output predictions above or equal to this value. Set a value in range [0, 1], where a higher value decreases the number of detections produced by the model and increases its speed during inference. \n",
    "\n",
    "We choose to set a low value (1%) for the model confidence threshold and then use a higher value at a later stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the desired confidence threshold\n",
    "conf_thresh = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained SSD model\n",
    "In order to run the head detection model first you must download the `.h5` file that contains the model and the trained weights. To do so, run the code in [section 1.1](#download_cell).\n",
    "\n",
    "Once downloaded, you can either build a new model and load the trained weights into it ([section 1.2](#build_cell)) or just load the ready to use model ([section 1.3](#load_cell)). The first option allows you to configure some model parameters, while the latter loads the original model's configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='download_cell'></a>\n",
    "### 1.1 Download the model's .h5 file\n",
    "First, we download the model's file from the server to this repository's `data/models` directory. We provide a simple script which will do this task for you, which you can execute by running the next cell. NOTE: this script requires `curl`to be installed in your system. \n",
    "\n",
    "In case you prefer to download the model manually, you can download it using the following links:\n",
    " - [Python versions <= 3.5](https://drive.google.com/open?id=12cqKTPtQBAu780219hEbST7VwQuf6xDH).\n",
    " - [Python versions >= 3.6](https://drive.google.com/open?id=1vlmKOBtaT7eAd4_WcAv5MLBn7q_SWXoh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Determine which script to use\n",
    "script_path = \"download_model_py%s.sh\" % model_version\n",
    "# Download the model file into the \"data\" directory\n",
    "os.chdir('./data/')\n",
    "if script_path in os.listdir(os.getcwd()):\n",
    "    print(\"Downloading model...\")\n",
    "    subprocess.call('./' + script_path)\n",
    "    print(\"Download finished.\")\n",
    "# Restore the working directory path\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='build_cell'></a>\n",
    "### 1.2 Build the model and load the trained weights into it\n",
    "You can build a new model and load the provided weights into it, which allows some degree of personalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1: Build the Keras model\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "model = ssd_512(image_size=(img_height, img_width, 3),\n",
    "                n_classes=1,\n",
    "                mode=model_mode,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # PASCAL VOC\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=[2, 1, 0],\n",
    "               confidence_thresh=conf_thresh,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "# 2: Load the trained weights into the model. Make sure the path correctly points to the model's .h5 file\n",
    "weights_path = './data/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187-py%s.h5' % model_version\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "# 4: OPTIONAL Save compiled model in inference mode so we can use option 1.3 in future executions\n",
    "# model.save('./data/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187-py%s.h5' % model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='load_cell'></a>\n",
    "### 1.3 Load the model as-is\n",
    "This option loads the downloaded model as it was compiled.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the path correctly points to the model's .h5 file\n",
    "weights_path = './data/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187-py%s.h5' % model_version\n",
    "\n",
    "# Create an SSDLoss object in order to pass that to the model loader\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, n_neg_min=0, alpha=1.0)\n",
    "\n",
    "# Clear previous models from memory.\n",
    "K.clear_session() \n",
    "\n",
    "# Finally load the model\n",
    "decode_layer = DecodeDetections(confidence_thresh=conf_thresh,\n",
    "                                iou_threshold=0.45,\n",
    "                                top_k=200,\n",
    "                                nms_max_output_size=400)\n",
    "if model_mode == 'inference_fast':\n",
    "    decode_layer = DecodeDetectionsFast(confidence_thresh=conf_thresh,\n",
    "                                        iou_threshold=0.45,\n",
    "                                        top_k=200,\n",
    "                                        nms_max_output_size=400)\n",
    "model = load_model(weights_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                                 'L2Normalization': L2Normalization,\n",
    "                                                 'DecodeDetections': decode_layer,\n",
    "                                                 'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load example images\n",
    "\n",
    "Load some images for which you'd like the model to make predictions. There are some demo images available in this repository's `examples`directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Original images array\n",
    "orig_images = [] \n",
    "# Resized images array\n",
    "input_images = []\n",
    "\n",
    "# We'll only load one image in this example.\n",
    "img_path = 'examples/people_drinking.jpg'\n",
    "# img_path = 'examples/fish_bike.jpg'\n",
    "# img_path = 'examples/rugby_players.jpg'\n",
    "\n",
    "# Load the original image (used to display results)\n",
    "orig_images.append(image.load_img(img_path))\n",
    "# Load the image resized to the model's input size\n",
    "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "img = image.img_to_array(img)\n",
    "input_images.append(img)\n",
    "input_images = np.array(input_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions\n",
    "Now we feed the example images into the network to obtain the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(input_images)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred` contains a fixed number of predictions per batch item (200 if you use the original model configuration), many of which are low-confidence predictions or dummy entries. We therefore need to apply a confidence threshold to filter out the bad predictions. Set this confidence threshold value how you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "confidence_threshold = 0.25\n",
    "\n",
    "# Perform confidence thresholding.\n",
    "y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "\n",
    "# Convert the predictions for the original image.\n",
    "# y_pred_thresh_inv = apply_inverse_transforms(y_pred_thresh, batch_inverse_transforms)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_thresh[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the predictions\n",
    "\n",
    "We just resized the input image above and made predictions on the distorted image. We'd like to visualize the predictions on the image in its original size though, so below we'll transform the coordinates of the predicted boxes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display the image and draw the predicted boxes onto it.\n",
    "\n",
    "# Set the colors for the bounding boxes\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "classes = ['background', 'head']\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.imshow(orig_images[0])\n",
    "\n",
    "current_axis = plt.gca()\n",
    "\n",
    "for box in y_pred_thresh[0]:\n",
    "    # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "    xmin = box[2] * np.array(orig_images[0]).shape[1] / img_width\n",
    "    ymin = box[3] * np.array(orig_images[0]).shape[0] / img_height\n",
    "    xmax = box[4] * np.array(orig_images[0]).shape[1] / img_width\n",
    "    ymax = box[5] * np.array(orig_images[0]).shape[0] / img_height\n",
    "    color = colors[int(box[0])]\n",
    "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
    "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
